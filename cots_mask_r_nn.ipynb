{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cots-mask-r-nn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "private_outputs": true,
      "authorship_tag": "ABX9TyPXB2KaAwCkdXY3J0j/nV+7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raitharnett/tensorflow-great-barrier-reef/blob/main/cots_mask_r_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "metadata": {
        "id": "v3fKktwKEhB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
        "python -m pip install --upgrade pip\n",
        "pip install --upgrade --force-reinstall --no-deps kaggle\n",
        "kaggle competitions download -c tensorflow-great-barrier-reef\n",
        "unzip -d  tensorflow-great-barrier-reef tensorflow-great-barrier-reef.zip "
      ],
      "metadata": {
        "id": "HWu4Wz8SEdcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "i-xN7kClw-iY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "python -m pip install --upgrade pip\n",
        "git clone https://github.com/tensorflow/models.git \n",
        "git clone --depth 1 https://github.com/tensorflow/models\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ],
      "metadata": {
        "id": "fHVHJVwAjnnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "wget http://download.tensorflow.org/models/object_detection/tf2/20200711/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8.tar.gz \n",
        "tar -xvzf mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8.tar.gz "
      ],
      "metadata": {
        "id": "A5jbbAUdHsWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IysfaTBTNOa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as pltls\n",
        "import pandas as pd\n",
        "import io\n",
        "import scipy.misc\n",
        "import shutil\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from six.moves.urllib.request import urlopen\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from object_detection.utils import dataset_util\n",
        "from object_detection.dataset_tools import tf_record_creation_util\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "from sklearn.model_selection import train_test_split\n",
        "import contextlib2\n",
        "from pathlib import Path\n",
        "from enum import Enum\n",
        "\n",
        "class COTSClass(Enum):\n",
        "  COTS = 1\n",
        "  \n",
        "%matplotlib inline\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "print(f\"TF version: {tf.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# path constants\n",
        "COTS_DATA_ROOT = '/content/'\n",
        "COTS_DATA =  os.path.join(COTS_DATA_ROOT,'tensorflow-great-barrier-reef')\n",
        "COTS_DATA_IMAGES = os.path.join(COTS_DATA,'train_images')\n",
        "COTS_DATASET = '/content/dataset'\n",
        "Path(COTS_DATASET).mkdir(parents=True, exist_ok=True)\n",
        "COTS_DATA_TRAIN_TF_RECORDS = f'{COTS_DATASET}/train'\n",
        "COTS_DATA_TEST_TF_RECORDS = f'{COTS_DATASET}/test'"
      ],
      "metadata": {
        "id": "QK1QL73PeTfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load COTS data\n",
        "def cots_annotations(data):\n",
        "  import json\n",
        "  return json.loads(data.replace(\"'\", '\"'))\n",
        "\n",
        "def cots_image_path(row):\n",
        "  return  os.path.join(COTS_DATA_IMAGES,\n",
        "                       f\"video_{row.video_id}\",\n",
        "                       f\"{row.video_frame}.jpg\")\n",
        "\n",
        "cots_df = pd.read_csv(os.path.join(COTS_DATA,'train.csv'), converters={'annotations':cots_annotations})\n",
        "cots_df['image_path'] = cots_df.apply(cots_image_path, axis=1)\n",
        "cots_train_test_split = train_test_split(cots_df, train_size = 0.8)"
      ],
      "metadata": {
        "id": "JT7M7hELeL6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FORMAT = 'jpeg'.encode('utf8')\n",
        "CLASS_NAME = COTSClass.COTS.name.encode('utf8')\n",
        "\n",
        "def create_cots_tf_example(row): \n",
        "  contents = tf.io.read_file(row.image_path)\n",
        "  image = tf.io.decode_jpeg(contents, channels=3)\n",
        "  h,w,_ = image.shape\n",
        "  filename = row.image_id.encode('utf8')\n",
        "  boxes = np.array([[a['x'], a['x'] + a['width'], a['y'], a['y'] + a['height']] for a in row.annotations], dtype='float64')\n",
        "  xmin, xmax, ymin, ymax, classes_text, classes = [], [], [], [], [], []\n",
        "  if  (0 < boxes.size):\n",
        "    # normalize\n",
        "    boxes[:,[0,1]] *= 1/w\n",
        "    boxes[:,[2,3]] *= 1/h\n",
        "    xmin, xmax = np.transpose(boxes[:,[0,1]]).tolist()\n",
        "    ymin, ymax = np.transpose(boxes[:,[2,3]]).tolist()\n",
        "    classes_text = [CLASS_NAME for i in range(len(xmin))] \n",
        "    classes = [COTSClass.COTS.value for i in range(len(xmin))]\n",
        "  feature = { 'image/height': dataset_util.int64_feature(h),\n",
        "              'image/width': dataset_util.int64_feature(w),\n",
        "              'image/filename': dataset_util.bytes_feature(filename),\n",
        "              'image/source_id': dataset_util.bytes_feature(filename),\n",
        "              'image/encoded': dataset_util.bytes_feature(contents.numpy()),\n",
        "              'image/format': dataset_util.bytes_feature(FORMAT),\n",
        "              'image/object/bbox/xmin': dataset_util.float_list_feature(xmin),\n",
        "              'image/object/bbox/xmax': dataset_util.float_list_feature(xmax),\n",
        "              'image/object/bbox/ymin': dataset_util.float_list_feature(ymin),\n",
        "              'image/object/bbox/ymax': dataset_util.float_list_feature(ymax),\n",
        "              'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "              'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "            }\n",
        "  return tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\n",
        "def load_cots(df, base_path, num_shards=10):\n",
        "  with contextlib2.ExitStack() as stack:\n",
        "    records = tf_record_creation_util.open_sharded_output_tfrecords(stack, base_path, num_shards)\n",
        "    for index, row in df.iterrows():\n",
        "      example = create_cots_tf_example(row)\n",
        "      shard_index = index % num_shards\n",
        "      records[shard_index].write(example.SerializeToString())"
      ],
      "metadata": {
        "id": "364dxDVIGRwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cots_tf_record_keys = [COTS_DATA_TRAIN_TF_RECORDS, COTS_DATA_TEST_TF_RECORDS]\n",
        "cots_train_test_data = {cots_tf_record_keys[i]: cots_train_test_split[i] for i in range(len(cots_train_test_split))}\n",
        "for base_path, df in cots_train_test_data.items():\n",
        "  load_cots(df, base_path)"
      ],
      "metadata": {
        "id": "9ATsQdxxr6AX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from string import Template\n",
        "\n",
        "TRAINING_STEPS = 1000\n",
        "WARMUP_STEPS = 100\n",
        "BATCH_SIZE = 2\n",
        "\n",
        "MODEL_LABEL_MAP = \"/content/drive/MyDrive/cots/label_map.txt\"\n",
        "MODEL_PIPELINE_CONFIG_TEMPLATE = \"/content/drive/MyDrive/cots/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8.config\"\n",
        "\n",
        "\n",
        "COTS_MODEL_DIR='/content/drive/MyDrive/cots/mask_rcnn_inception_resnet_v2'\n",
        "\n",
        "PIPELINE_CONFIG_PATH = '/content/dataset/pipeline.config'\n",
        "LABEL_MAP_PATH = '/content/dataset/label_map.pbtxt'\n",
        "\n",
        "shutil.copy(MODEL_LABEL_MAP, LABEL_MAP_PATH)\n",
        "\n",
        "category_index = label_map_util.create_category_index_from_labelmap(LABEL_MAP_PATH, use_display_name=True)\n",
        "\n",
        "with open(MODEL_PIPELINE_CONFIG_TEMPLATE, mode='r') as f:\n",
        "  config_file_template = f.read()\n",
        "pipeline = Template(config_file_template).substitute(training_steps=TRAINING_STEPS, warmup_steps=WARMUP_STEPS, batch_size=BATCH_SIZE)\n",
        "with open(PIPELINE_CONFIG_PATH, mode='w') as f:\n",
        "  f.write(pipeline)"
      ],
      "metadata": {
        "id": "FK6GbHB8wwPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash -s \"$COTS_MODEL_DIR\" \"$PIPELINE_CONFIG_PATH\"\n",
        "MODEL_DIR=$1\n",
        "PIPELINE_CONFIG_PATH=$2\n",
        "# train model\n",
        "python models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path=$PIPELINE_CONFIG_PATH \\\n",
        "    --model_dir=$MODEL_DIR \\\n",
        "    --alsologtostderr\n",
        "# # evaluate model\n",
        "# python models/research/object_detection/model_main_tf2.py \\\n",
        "#     --pipeline_config_path=$PIPELINE_CONFIG_PATH \\\n",
        "#     --model_dir=$MODEL_DIR \\\n",
        "#     --checkpoint_dir=$MODEL_DIR \\\n",
        "#     --eval_timeout=0 \\\n",
        "#     --alsologtostderr\n",
        "# # save model\n",
        "# python models/research/object_detection/exporter_main_v2.py \\\n",
        "#     --input_type image_tensor \\\n",
        "#     --pipeline_config_path=$PIPELINE_CONFIG_PATH \\\n",
        "#     --trained_checkpoint_dir=$MODEL_DIR \\\n",
        "#     --output_directory=$MODEL_DIR/output \\\n",
        "#     --alsologtostderr"
      ],
      "metadata": {
        "id": "UK6ZwU9V92hZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ub_2nx5Lf-YZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detector = hub.load(\"https://tfhub.dev/tensorflow/mask_rcnn/inception_resnet_v2_1024x1024/1\")"
      ],
      "metadata": {
        "id": "IITzpM1ngUKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv \n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "COTS_DATA = '/content/drive/MyDrive/cots/tensorflow-great-barrier-reef'\n",
        "COTS_DATA_IMAGES = os.path.join(COTS_DATA,'train_images')\n",
        "PATH_TO_LABELS = './models/research/object_detection/data/mscoco_label_map.pbtxt'\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n",
        "cots_df = pd.read_csv(os.path.join(COTS_DATA,'train.csv'))\n",
        "cots_df['image_path'] = cots_df.apply(lambda r: os.path.join(COTS_DATA_IMAGES,f\"video_{r.video_id}\",f\"{r.video_frame}.jpg\"), axis=1)\n",
        "cots_df_elements = cots_df.sample(n=1)\n",
        "\n",
        "for _, row in cots_df_elements.iterrows():\n",
        "  image_tensor = tf.io.decode_jpeg(tf.io.read_file(row.image_path), channels=3)\n",
        "  detector_output = detector(image_tensor[tf.newaxis, ...])\n",
        "  result = {key:value.numpy() for key,value in detector_output.items()}\n",
        "  print(result['num_detections'])\n",
        "  label_id_offset = 0\n",
        "  image_np =  image_tensor.numpy()\n",
        "  image_np_with_mask = image_tensor.numpy().copy()\n",
        "  if 'detection_masks' in result:\n",
        "    # we need to convert np.arrays to tensors\n",
        "    detection_masks = tf.convert_to_tensor(result['detection_masks'][0])\n",
        "    detection_boxes = tf.convert_to_tensor(result['detection_boxes'][0])\n",
        "\n",
        "    # Reframe the bbox mask to the image size.\n",
        "    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "              detection_masks, detection_boxes,\n",
        "                image_np.shape[0], image_np.shape[1])\n",
        "    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
        "                                        tf.uint8)\n",
        "    result['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
        "\n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np_with_mask,\n",
        "        result['detection_boxes'][0],\n",
        "        (result['detection_classes'][0] + label_id_offset).astype(int),\n",
        "        result['detection_scores'][0],\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        max_boxes_to_draw=200,\n",
        "        min_score_thresh=.30,\n",
        "        agnostic_mode=False,\n",
        "        instance_masks=result.get('detection_masks_reframed', None),\n",
        "        line_thickness=8)\n",
        "\n",
        "  plt.figure(figsize=(24,32))\n",
        "  plt.imshow(image_np_with_mask)\n",
        "  plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HpunbSQF4RNq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}