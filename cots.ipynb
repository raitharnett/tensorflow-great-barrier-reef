{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cots.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMxN0ZAydHUY+zAJpSzImv6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raitharnett/tensorflow-great-barrier-reef/blob/main/cots.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "5f0jp4VQO1tw"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install --upgrade --force-reinstall --no-deps kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%alias install_kaggle mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "yCKc7Lq8Qh8h"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%alias download_cots_data kaggle competitions download -c tensorflow-great-barrier-reef --force >& /dev/null"
      ],
      "metadata": {
        "id": "OeJ5hgQDRBgk"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%alias install_cots_data unzip -d  tensorflow-great-barrier-reef tensorflow-great-barrier-reef.zip >& /dev/null"
      ],
      "metadata": {
        "id": "Es3QY-0PSvuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download tensorflow-great-barrier-reef data and import library used to submit predictions\n",
        "from google.colab import files\n",
        "import os\n",
        "import sys\n",
        "COTS_DATA = '/content/tensorflow-great-barrier-reef'\n",
        "if not os.path.isdir(COTS_DATA):\n",
        "  uploaded = files.upload()\n",
        "  for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "        name=fn, length=len(uploaded[fn])))\n",
        "  %install_kaggle\n",
        "  %download_cots_data\n",
        "  %install_cots_data\n",
        "sys.path.insert(0, COTS_DATA)\n",
        "import greatbarrierreef"
      ],
      "metadata": {
        "id": "xTR1OLloPXGb"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "# Clone the tensorflow models repository if it doesn't already exist\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "metadata": {
        "id": "pZTml-LHSLNO"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the Object Detection API\n",
        "%%capture\n",
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ],
      "metadata": {
        "id": "lEy1HAaxSViq"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import contextlib2\n",
        "import io\n",
        "import IPython\n",
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "import pathlib\n",
        "import pandas as pd\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import time\n",
        "\n",
        "from PIL import Image, ImageDraw\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)"
      ],
      "metadata": {
        "id": "Mq8gBnCOT3-D"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from object_detection.utils import dataset_util\n",
        "from object_detection.dataset_tools import tf_record_creation_util\n",
        "COTS_DATA_IMAGES = os.path.join(COTS_DATA,'train_images')\n",
        "def createCOTSTFExample(row):\n",
        "  with tf.io.gfile.GFile(row.image_path, 'rb') as fid:\n",
        "    encodedJpg = fid.read()\n",
        "  encodedJpgIO = io.BytesIO(encodedJpg)\n",
        "  image = Image.open(encodedJpgIO)\n",
        "  width = image.size[0]\n",
        "  height = image.size[1]\n",
        "  fileName = f'{row.image_id}'.encode('utf8')\n",
        "  imageFormat = 'jpeg'.encode('utf8')\n",
        "  classesText = []\n",
        "  classes = []\n",
        "  annotations = json.loads(row.annotations.replace(\"'\", '\"'))\n",
        "  xmin = []\n",
        "  ymin = []\n",
        "  xmax = []\n",
        "  ymax = []\n",
        "  for annotation in annotations:\n",
        "    xmin.append(annotation['x'] / width) \n",
        "    xmax.append((annotation['x'] + annotation['width']) / width) \n",
        "    ymin.append(annotation['y'] / height) \n",
        "    ymax.append((annotation['y'] + annotation['height']) / height) \n",
        "    classesText.append('COTS'.encode('utf8'))\n",
        "    classes.append(1)\n",
        "\n",
        "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "      'image/height': dataset_util.int64_feature(height),\n",
        "      'image/width': dataset_util.int64_feature(width),\n",
        "      'image/filename': dataset_util.bytes_feature(fileName),\n",
        "      'image/source_id': dataset_util.bytes_feature(fileName),\n",
        "      'image/encoded': dataset_util.bytes_feature(encodedJpg),\n",
        "      'image/format': dataset_util.bytes_feature(imageFormat),\n",
        "      'image/object/bbox/xmin': dataset_util.float_list_feature(xmin),\n",
        "      'image/object/bbox/xmax': dataset_util.float_list_feature(xmax),\n",
        "      'image/object/bbox/ymin': dataset_util.float_list_feature(ymin),\n",
        "      'image/object/bbox/ymax': dataset_util.float_list_feature(ymax),\n",
        "      'image/object/class/text': dataset_util.bytes_list_feature(classesText),\n",
        "      'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "    }))\n",
        "\n",
        "\n",
        "\n",
        "def loadCOTS(df):\n",
        "  for _, cotsRow in df.iterrows():\n",
        "    createCOTSTFExample(cotsRow) \n"
      ],
      "metadata": {
        "id": "rL8pmBhePr6D"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cotsDF = pd.read_csv(os.path.join(COTS_DATA,'train.csv'))\n",
        "# image_path\n",
        "cotsDF['image_path'] = cotsDF.apply(lambda r: os.path.join(COTS_DATA_IMAGES,f\"video_{r.video_id}\",f\"{r.video_frame}.jpg\"), axis=1)\n",
        "# training data load\n",
        "loadCOTS(cotsDF[:10])\n",
        "print(cotsDF.head())\n",
        "# cotsDF.groupby(['video_id','video_frame'])['sequence'].count()\n",
        "# # ['sequence'].max()"
      ],
      "metadata": {
        "id": "sI26jIpPd0En",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79f59955-e522-411d-c79d-46464980d942"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   video_id  sequence  video_frame  sequence_frame image_id annotations  \\\n",
            "0         0     40258            0               0      0-0          []   \n",
            "1         0     40258            1               1      0-1          []   \n",
            "2         0     40258            2               2      0-2          []   \n",
            "3         0     40258            3               3      0-3          []   \n",
            "4         0     40258            4               4      0-4          []   \n",
            "\n",
            "                                          image_path  \n",
            "0  /content/tensorflow-great-barrier-reef/train_i...  \n",
            "1  /content/tensorflow-great-barrier-reef/train_i...  \n",
            "2  /content/tensorflow-great-barrier-reef/train_i...  \n",
            "3  /content/tensorflow-great-barrier-reef/train_i...  \n",
            "4  /content/tensorflow-great-barrier-reef/train_i...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "43Es-V1bMdzE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}